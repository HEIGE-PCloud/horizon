{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_data(path: Path) -> pd.DataFrame:\n",
    "    data = pd.read_csv(path)\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"job_description\": data[\n",
    "                [\"company_profile\", \"description\", \"requirements\", \"benefits\"]\n",
    "            ]\n",
    "            .fillna(\"\")\n",
    "            .agg(\" \".join, axis=1),\n",
    "            \"fraudulent\": data[\"fraudulent\"],\n",
    "        }\n",
    "    )\n",
    "    data = data.drop_duplicates(subset=[\"job_description\"], keep=\"first\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_data(data: pd.DataFrame):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data[\"job_description\"],\n",
    "        data[\"fraudulent\"],\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=data[\"fraudulent\"],\n",
    "    )\n",
    "\n",
    "    # Convert to DataFrame for easy manipulation\n",
    "    train_df = pd.DataFrame({'job_description': X_train, 'fraudulent': y_train})\n",
    "\n",
    "    # Separate fraudulent (y=1) and non-fraudulent (y=0) samples\n",
    "    fraudulent_df = train_df[train_df['fraudulent'] == 1]\n",
    "    non_fraudulent_df = train_df[train_df['fraudulent'] == 0]\n",
    "    print(fraudulent_df.shape, non_fraudulent_df.shape)\n",
    "\n",
    "    # Oversample each fraudulent job description exactly 21 times\n",
    "    fraudulent_df_oversampled = pd.concat([fraudulent_df] * 21, ignore_index=True)\n",
    "\n",
    "    # Combine the oversampled fraudulent data with the original non-fraudulent data\n",
    "    train_df_oversampled = pd.concat([non_fraudulent_df, fraudulent_df_oversampled], ignore_index=True)\n",
    "\n",
    "    # Shuffle the data\n",
    "    train_df_oversampled = train_df_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Extract the oversampled X_train and y_train\n",
    "    X_train: pd.Series[str] = train_df_oversampled['job_description']\n",
    "    y_train: pd.Series[int] = train_df_oversampled['fraudulent']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shivamb/real-or-fake-fake-jobposting-prediction\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "from pathlib import Path\n",
    "data = load_data(Path(path + \"/fake_job_postings.csv\"))\n",
    "X_train, X_test, y_train, y_test = split_data(data)\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Optional: disable wandb if you don't wish to log experiments online\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Custom Dataset class to handle job descriptions and labels\n",
    "class JobDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=8192):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            texts (pd.Series or list): Job descriptions.\n",
    "            labels (pd.Series or list): Corresponding binary labels (0 or 1).\n",
    "            tokenizer: The LLAMA tokenizer.\n",
    "            max_length (int): Maximum sequence length.\n",
    "        \"\"\"\n",
    "        self.texts = texts.tolist() if hasattr(texts, 'tolist') else texts\n",
    "        self.labels = labels.tolist() if hasattr(labels, 'tolist') else labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # Remove extra batch dimension\n",
    "        encoding = {key: tensor.squeeze(0) for key, tensor in encoding.items()}\n",
    "        encoding[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        return encoding\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B\"  # Adjust if necessary based on available models\n",
    "\n",
    "# Load the tokenizer and model (with a classification head)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Optional: enable gradient checkpointing to reduce memory usage\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Create the dataset objects\n",
    "train_dataset = JobDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = JobDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "# Define a compute_metrics function to evaluate accuracy, precision, recall, and f1\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Set up the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,  # Adjust based on your GPU memory; LLAMA models are heavy\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
