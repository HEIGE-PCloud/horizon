{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6wVvWIqVo6e"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def load_data(path: Path) -> pd.DataFrame:\n",
        "    data = pd.read_csv(path)\n",
        "    data = pd.DataFrame(\n",
        "        {\n",
        "            \"job_description\": data[\n",
        "                [\"company_profile\", \"description\", \"requirements\", \"benefits\"]\n",
        "            ]\n",
        "            .fillna(\"\")\n",
        "            .agg(\" \".join, axis=1),\n",
        "            \"fraudulent\": data[\"fraudulent\"],\n",
        "        }\n",
        "    )\n",
        "    data = data.drop_duplicates(subset=[\"job_description\"], keep=\"first\")\n",
        "    return data\n",
        "\n",
        "\n",
        "def split_data(data: pd.DataFrame):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        data[\"job_description\"],\n",
        "        data[\"fraudulent\"],\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=data[\"fraudulent\"],\n",
        "    )\n",
        "\n",
        "    # Convert to DataFrame for easy manipulation\n",
        "    train_df = pd.DataFrame({'job_description': X_train, 'fraudulent': y_train})\n",
        "\n",
        "    # Separate fraudulent (y=1) and non-fraudulent (y=0) samples\n",
        "    fraudulent_df = train_df[train_df['fraudulent'] == 1]\n",
        "    non_fraudulent_df = train_df[train_df['fraudulent'] == 0]\n",
        "    print(fraudulent_df.shape, non_fraudulent_df.shape)\n",
        "\n",
        "    # Oversample each fraudulent job description exactly 21 times\n",
        "    fraudulent_df_oversampled = pd.concat([fraudulent_df] * 21, ignore_index=True)\n",
        "\n",
        "    # Combine the oversampled fraudulent data with the original non-fraudulent data\n",
        "    train_df_oversampled = pd.concat([non_fraudulent_df, fraudulent_df_oversampled], ignore_index=True)\n",
        "\n",
        "    # Shuffle the data\n",
        "    train_df_oversampled = train_df_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Extract the oversampled X_train and y_train\n",
        "    X_train: pd.Series[str] = train_df_oversampled['job_description']\n",
        "    y_train: pd.Series[int] = train_df_oversampled['fraudulent']\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "nrxrPN_1VvdQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6QZyqxRVo6k",
        "outputId": "77d41769-007a-4d63-f73f-7926e2b8d12b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/real-or-fake-fake-jobposting-prediction?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0.00/16.1M [00:00<?, ?B/s]"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shivamb/real-or-fake-fake-jobposting-prediction\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "from pathlib import Path\n",
        "data = load_data(path + \"/fake_job_postings.csv\")\n",
        "X_train, X_test, y_train, y_test = split_data(data)\n",
        "print(X_train.head())\n",
        "print(y_train.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "k0yrSINjVo6l",
        "outputId": "eaf9350e-47a3-4f37-9ce2-8ec7eecd87a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='4374' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  34/4374 00:50 < 1:53:31, 0.64 it/s, Epoch 0.02/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Custom Dataset to handle our job descriptions and labels\n",
        "class JobDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (pd.Series or list): The job descriptions.\n",
        "            labels (pd.Series or list): The corresponding labels (0 or 1).\n",
        "            tokenizer (PreTrainedTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum token length for each text.\n",
        "        \"\"\"\n",
        "        # Convert pandas Series to list if needed\n",
        "        self.texts = texts.tolist() if hasattr(texts, 'tolist') else texts\n",
        "        self.labels = labels.tolist() if hasattr(labels, 'tolist') else labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        # Tokenize the text with truncation and padding\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        # Squeeze to remove the batch dimension\n",
        "        encoding = {key: tensor.squeeze(0) for key, tensor in encoding.items()}\n",
        "        encoding['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "        return encoding\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test have been defined as in your preprocessing step\n",
        "# Create our dataset objects\n",
        "train_dataset = JobDataset(X_train, y_train, tokenizer, max_length=512)\n",
        "test_dataset = JobDataset(X_test, y_test, tokenizer, max_length=512)\n",
        "\n",
        "# Load pre-trained BERT model for sequence classification (binary classification => num_labels=2)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Define a metric function for evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',             # output directory\n",
        "    num_train_epochs=3,                 # total number of training epochs\n",
        "    per_device_train_batch_size=16,     # batch size per device during training\n",
        "    per_device_eval_batch_size=16,      # batch size for evaluation\n",
        "    evaluation_strategy='epoch',        # evaluate at the end of each epoch\n",
        "    save_strategy='epoch',              # save checkpoint at the end of each epoch\n",
        "    logging_dir='./logs',               # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,        # load the best model when finished training\n",
        "    metric_for_best_model=\"accuracy\",   # use accuracy to evaluate the best model\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Optionally, evaluate the model on the test set after training\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Evaluation results:\", eval_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwqWlxsIVo6m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}